#!/usr/bin/env python3

import argparse
import sys
import os
import requests
from .analyzer import RepoAnalyzer
from typing import Optional, List
from datetime import datetime
import json

def log(message: str):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {message}")

GITHUB_BASE_URL = "https://github.com/"

class FriendlyArgumentParser(argparse.ArgumentParser):
    def error(self, message):
        if '--format' in message:
            log(f"âŒ ì¸ì ì˜¤ë¥˜: {message}")
            log("ì‚¬ìš© ê°€ëŠ¥í•œ --format ê°’: table, text, chart, all")
        else:
            super().error(message)
        sys.exit(2)

def validate_repo_format(repo: str) -> bool:
    parts = repo.split("/")
    return len(parts) == 2 and all(parts)

def check_github_repo_exists(repo: str) -> bool:
    url = f"https://api.github.com/repos/{repo}"
    response = requests.get(url)
    if response.status_code == 403:
        log("âš ï¸ GitHub API ìš”ì²­ ì‹¤íŒ¨: 403 (ë¹„ì¸ì¦ ìƒíƒœë¡œ ìš”ì²­ íšŸìˆ˜ ì´ˆê³¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
        log("â„¹ï¸ í•´ê²° ë°©ë²•: --token ì˜µì…˜ìœ¼ë¡œ GitHub Access Tokenì„ ì „ë‹¬í•´ë³´ì„¸ìš”.")
        return False
    return response.status_code == 200

def check_rate_limit(token: Optional[str] = None) -> None:
    headers = {}
    if token:
        headers["Authorization"] = f"token {token}"
    response = requests.get("https://api.github.com/rate_limit", headers=headers)
    if response.status_code == 200:
        data = response.json()
        core = data.get("resources", {}).get("core", {})
        remaining = core.get("remaining", "N/A")
        limit = core.get("limit", "N/A")
        log(f"GitHub API ìš”ì²­ ê°€ëŠ¥ íšŸìˆ˜: {remaining} / {limit}")
    else:
        log(f"API ìš”ì²­ ì œí•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (status code: {response.status_code}).")

def parse_arguments() -> argparse.Namespace:
    parser = FriendlyArgumentParser(
        prog="python -m reposcore",
        usage="python -m reposcore [-h] [owner/repo ...] [--output dir_name] [--format {table,text,chart,all}] [--check-limit] [--show-participants]",
        description="ì˜¤í”ˆ ì†ŒìŠ¤ ìˆ˜ì—…ìš© ë ˆí¬ì§€í† ë¦¬ì˜ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•˜ëŠ” CLI ë„êµ¬"
    )
    parser.add_argument(
        "repository",
        type=str,
        nargs="+",
        metavar="owner/repo",
        help="ë¶„ì„í•  GitHub ì €ì¥ì†Œë“¤ (í˜•ì‹: 'ì†Œìœ ì/ì €ì¥ì†Œ'). ì—¬ëŸ¬ ì €ì¥ì†Œì˜ ê²½ìš° ê³µë°± í˜¹ì€ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="results",
        metavar="dir_name",
        help="ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'results')"
    )
    parser.add_argument(
        "--format",
        choices=["table", "text", "chart", "all"],
        nargs='+',
        default=["all"],
        metavar="{table,text,chart,all}",
        help="ê²°ê³¼ ì¶œë ¥ í˜•ì‹ ì„ íƒ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥, ì˜ˆ: --format table chart). ì˜µì…˜: 'table', 'text', 'chart', 'all'"
    )
    parser.add_argument(
        "--use-cache",
        action="store_true",
        help="participants ë°ì´í„°ë¥¼ ìºì‹œì—ì„œ ë¶ˆëŸ¬ì˜¬ì§€ ì—¬ë¶€ (ê¸°ë³¸: APIë¥¼ í†µí•´ ìƒˆë¡œ ìˆ˜ì§‘)"
    )
    parser.add_argument(
        "--token",
        type=str,
        help="API ìš”ì²­ ì œí•œ í•´ì œë¥¼ ìœ„í•œ ê¹ƒí—ˆë¸Œ ê°œì¸ ì•¡ì„¸ìŠ¤ í† í°"
    )
    parser.add_argument(
        "--check-limit",
        action="store_true",
        help="í˜„ì¬ GitHub API ìš”ì²­ ê°€ëŠ¥ íšŸìˆ˜ì™€ ì „ì²´ í•œë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        "--show-participants",
        action="store_true",
        help="ì°¸ì—¬ìë³„ í™œë™ ë‚´ì—­ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
    )
    return parser.parse_args()

def merge_participants(overall: dict, new_data: dict) -> dict:
    for user, activities in new_data.items():
        if user not in overall:
            overall[user] = activities.copy()
        else:
            for key, value in activities.items():
                overall[user][key] = overall[user].get(key, 0) + value
    return overall

def main():
    args = parse_arguments()
    github_token = args.token or os.getenv('GITHUB_TOKEN')

    if args.check_limit:
        check_rate_limit(token=github_token)
        sys.exit(0)

    repositories: List[str] = []
    for repo in args.repository:
        if "," in repo:
            repositories.extend([r.strip() for r in repo.split(",") if r.strip()])
        else:
            repositories.append(repo)
    repositories = list(dict.fromkeys(repositories))

    for repo in repositories:
        if not validate_repo_format(repo):
            log(f"ì˜¤ë¥˜: ì €ì¥ì†Œ '{repo}'ëŠ” 'owner/repo' í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ) 'oss2025hnu/reposcore-py'")
            sys.exit(1)
        if not check_github_repo_exists(repo):
            log(f"ì…ë ¥í•œ ì €ì¥ì†Œ '{repo}'ê°€ ê¹ƒí—ˆë¸Œì— ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.")

    log(f"ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘: {', '.join(repositories)}")

    overall_participants = {}

    for repo in repositories:
        log(f"ë¶„ì„ ì‹œì‘: {repo}")
        analyzer = RepoAnalyzer(repo, token=github_token, show_participants=args.show_participants)
        cache_file_name = f"cache_{repo.replace('/', '_')}.json"
        cache_path = os.path.join(args.output, cache_file_name)

        os.makedirs(args.output, exist_ok=True)

        if args.use_cache and os.path.exists(cache_path):
            log(f"âœ… ìºì‹œ íŒŒì¼({cache_file_name})ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ìºì‹œì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
            with open(cache_path, "r", encoding="utf-8") as f:
                analyzer.participants = json.load(f)
        else:
            log(f"ğŸ”„ ìºì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê±°ë‚˜ ìºì‹œ íŒŒì¼({cache_file_name})ì´ ì—†ìŠµë‹ˆë‹¤. GitHub APIë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            analyzer.collect_PRs_and_issues()
            if not getattr(analyzer, "_data_collected", True):
                log("âŒ GitHub API ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šê³  ì¢…ë£Œí•©ë‹ˆë‹¤.")
                sys.exit(1)
            with open(cache_path, "w", encoding="utf-8") as f:
                json.dump(analyzer.participants, f, indent=2, ensure_ascii=False)

        overall_participants = merge_participants(overall_participants, analyzer.participants)
        log(f"ë¶„ì„ ì™„ë£Œ: {repo}")

    aggregator = RepoAnalyzer("multiple_repos", token=github_token)
    aggregator.participants = overall_participants

    try:
        scores = aggregator.calculate_scores()
        formats = set(args.format)

        os.makedirs(args.output, exist_ok=True)

        if "all" in formats:
            formats = {"table", "text", "chart"}

        if "table" in formats:
            table_path = os.path.join(args.output, "table.csv")
            aggregator.generate_table(scores, save_path=table_path)
            log(f"\nCSV ì €ì¥ ì™„ë£Œ: {table_path}")

        if "text" in formats:
            txt_path = os.path.join(args.output, "table.txt")
            aggregator.generate_text(scores, txt_path)
            log(f"\ní…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {txt_path}")

        if "chart" in formats:
            chart_path = os.path.join(args.output, "chart.png")
            aggregator.generate_chart(scores, save_path=chart_path)
            log(f"\nì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {chart_path}")

    except Exception as e:
        log(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()
